%Neural Networks (NN) have been known as an important data mining technique used in classification, clustering, etc. A neural network is defined by a set of input, hidden and output layer. Each layer contains several nodes depending on user requirements. There are connection between nodes in input, hidden and output layer. Those connection represent weights between nodes. 
%In this paper, we describe Backpropagation (BP) algorithm which is one of the most popular algorithm in NN. Moreover, we also discuss an advantage and disadvantage of this algorithm. Finally, we show that BP is quite often used in practice. 

% The application of information retrieval (IR) techniques to seach tasks in software engineering is made difficult by the lexical gap between search queries (i.e., natural language) and retrieved documents (i.e., programming language). We often see this case in bug and feature location, community question answering, or more generally the communication between technical personnel and non-technical stake holders in a software project. Many previous studies treated the program elements as well as bug reports based on bag-of-words features, and estimate the correlation between the bug report and program element by measuring similarity in the same lexical feature space. However, the traditional approaches often fail to capture the word meaning for either long or short duration of time.  

Software defect prediction help developers to find bugs and prioritize their testing efforts. The traditional approaches focus on manually designing features encoding the characteristics of programs and employing different machine algorithms to construct defect prediction models. However, the manual defect features often fail to capture the semantic differences of programs, hence the prediction models may not be accurate. 
In this paper, we propose bridging the lexical gap between programs' semantics and defect prediction features by projecting natural language statements and programming element. Specifically, we introduce semi-supervised model inspired by autoencoder to learn semantic representation of source code as well as detect program's defect. Our framework is not only learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs), but also construct classification model to detect program elements containing future bug. The experimental results show that our approach significantly outperforms the traditional approaches in defect prediction problem. 

%\textcolor{red}{write something about the results}


%we introduce deep learning model to remember the long-short term behaviour of program elements as well as bug reports. Moreover, we also apply topic modeling to expanse the program elements and bug reports, the traditional IR techniques employ to estimate the relationship between program elements and bug reports. The weights combination between two proposed approaches are learned to determine the program element related to bug report.  \textcolor{red}{Talk about experimental results later}.
