This section presents our experimental results. We examine the performance of our proposed DDA approach in both within-project and cross-project defect prediction setting. In the within-project setting, we use the source code of an older version of a project to construct the DDA model and evaluate this model based on the source code of the newer version of the project. In the cross-project setting, we randomly pick one project as a source project to build the DDA model and use the model to predict defects for a target project that is randomly picked from a set of projects that excludes the source project.

We answer the following research questions: 

\textbf{RQ1: In within-project defect prediction, does our proposed approach outperform traditional models generated by different machine learning algorithms using semantic features?}

We run experiments on four popular software projects. For each project, we construct defect prediction models using the training version and evaluate them in the testing version. Note that the training and testing are collected in two different timelines (i.e., version as of January $1^{st}$, 2015 and version as of July $1^{st}$, 2015).
%, each of which uses two versions of the same project collected in two different time-lines (see Table~\ref{tab:data}). The training data, which is the older version of these projects, are used to construct defect prediction models, and the testing data is used to evaluate the performance of our prediction models. 
Table~\ref{tab:within} shows the precision, recall and F1 score of different defect prediction models. The highest F1 scores are highlighted in bold. For example, the F1 of our approach is 46.7\% in Traccar project, while the best F1 is only 23.9\% with embedding features (using decision tree), and the best F1 is 20.7\% with AST features (using logistic regression). On average, the best baseline that uses AST features achieve an F1 score of 34.9\%, while the best baseline that uses semantic features constructed following~\cite{wang2016automatically} approach achieves an F1 score of 43.8\%. Our DDA approach beats these two baselines by achieving an F1 score of 52.4\%. The results demonstrate that we can improve the F1 score to be 8.6\% higher when compared with the best baseline. 


\textbf{RQ2: In cross-project defect prediction, does our proposed approach outperform traditional models generated by different machine learning algorithms using semantic features?}

%We also compare our DSSL model against Wang et al.~\cite{wang2016automatically} approach. Note that we also provide a bench-mark of within-project for a fair comparison. 
We evaluate eight pairs of projects. For each pair, we take two different projects for training and testing. Table~\ref{tab:cross} presents the precision, recall and F1 scores of our proposed method (DDA) vs. the best defect prediction models constructed based on embedding features. We employ naive Bayes algorithm to build defect prediction model from embedding features since this algorithm shows the best F1 in within-project (see Table~\ref{tab:within}). The best F1 scores are also in bold. For example, when the source project is Nuvolabase (training) and the target project is Checkstyle (testing). Our DDA achieves a F1 score of 66.7\% whereas the best defect prediction model used embedding features only achieves 45.3\%. In average, DDA achieves a F1 score of 36.4\%, which is a 5.6\% higher than F1 score of the best model that uses semantic features. It shows that our proposed DDA improves the performance of cross-project defect prediction. 

\textbf{RQ3: What is the training time of proposed approach?}
We run experiments on a NVIDIA DGX-1~\footnote{https://www.nvidia.com/en-us/data-center/dgx-1/} machine to construct the DDA model. We keep track of the training time that our server needs to build the DDA model on the four software projects for within-project problem. Table~\ref{tab:time} shows the training time which needs to build DDA model. In average, the training time for our proposed method varies from 5.67 seconds (Traccar) to 62.5 seconds (Checkstyle). On average, it takes 34.4 seconds to build the DDA model. Hence it proves that our DDA is applicable in practice.

%To answer this question, we use two different features to build defect prediction models. We run the experiments on 28 sets of software project, each of which uses two versions of the same project (see Table~\ref{tab:data}). The training data, which is the older version of these projects, are used to construct defect prediction models, and the testing data is used to evaluate the performance of our prediction models. Table~\ref{tab:dttree} shows the precision, recall and F1 of the defect prediction experiments. On average, code features achieve a F1 of 0.354, the semantic features constructed following~\cite{wang2016automatically} approaches achieve a F1 of 0.456, and our approach achieves a F1 of 0.510. The results demonstrate that we can improve the defect prediction F1 by 5.4\% on average on 28 software projects. 

%We also use code features and semantic features separately to build defect prediction models by using two alternative classification algorithm, i.e., logistic regression and Naive Bayes. Table~\ref{tab:lr} shows the precision, recall and F1 scores on SSA vs. two different defect prediction models constructed by code features and semantic features using logistic regression. On average, code features and semantic features achieve F1 of 0.421 and 0.432 respectively. It shows that our SSA model improve the performance of F1 by 8.9\% and 7.8\% compared to two defect prediction models built using logistic regression algorithm. Table~\ref{tab:nb} presents the results of defect prediction models code features and semantic features using Naive Bayes algorithm, and SSA approaches. We see that our SSA outperforms these two baseline approaches. Table~\ref{tab:all} shows the F1 results of our approach compared to the two code features and semantic features constructed be three different machine learning algorithms, i.e., decision tree, logistic regression, and Naive Bayes. It shows that SSA outperforms the other approaches on 28 software projects in average. 

%The results demonstrate
%that by using the semantic features automatically learned
%by DBN instead of the PROMISE features, we can improve
%the defect prediction F1 by 14.2% on average on 16 data
%sets. The average improvement in the precision and recall is
%14.7% and 11.5% respectively.
%Since the DBN algorithm has randomness, the generated
%features vary between dierent runs. Therefore, we run our
%DBN-based feature generation approach ve times for each
%experiment. Among the runs, the dierence in the generated
%features is at the level of 1.0e-20, which is too small to
%propagate to precision, recall, and F1. In other words, the
%precision, recall, and F1 of all ve runs are identical.

