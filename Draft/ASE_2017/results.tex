

This section presents our experimental results. We examine the performance of our propose approaches, i.e., deep semi-supervised learning (DSSL) in both within-project and cross-project defect prediction. In the within-project, we use the source code of an older time to construct DSSL model and evaluate this model based on source code of a recent time. For the cross-project, we randomly pick 1 project as source project to build defect prediction model and use the model to predict defect for a new project called target project.

We are trying to answer the following research questions: 

\textbf{RQ1: Does our proposed framework outperform the traditional models generated by different machine learning algorithms based on semantic features in within-project defect prediction?}

We run the experiments on four popular of software project, each of which uses two versions of the same project collected in two different time-lines (see Table~\ref{tab:data}). The training data, which is the older version of these projects, are used to construct defect prediction models, and the testing data is used to evaluate the performance of our prediction models. Table~\ref{tab:within} shows the precision, recall and F1 of the defect prediction experiments. On average, AST features achieve best F1 of 34.9\%, the semantic features constructed following~\cite{wang2016automatically} approach achieves the best F1 of 43.8\% using naive Bayes classification algorithm, and our deep semi-supervised learning (DSSL) achieves a F1 of 52.4\%. The results demonstrate that we can improve the defect prediction F1 by 8.6\% on average of four software projects. 


\textbf{RQ2: Does our proposed framework outperform the traditional models generated by different machine learning algorithms based on semantic features in cross-project defect prediction?}

\textbf{RQ3: What is the time cost of proposed framework}

%To answer this question, we use two different features to build defect prediction models. We run the experiments on 28 sets of software project, each of which uses two versions of the same project (see Table~\ref{tab:data}). The training data, which is the older version of these projects, are used to construct defect prediction models, and the testing data is used to evaluate the performance of our prediction models. Table~\ref{tab:dttree} shows the precision, recall and F1 of the defect prediction experiments. On average, code features achieve a F1 of 0.354, the semantic features constructed following~\cite{wang2016automatically} approaches achieve a F1 of 0.456, and our semi-supervised autoencoder (SSA) achieves a F1 of 0.510. The results demonstrate that we can improve the defect prediction F1 by 5.4\% on average on 28 software projects. 

We also use code features and semantic features separately to build defect prediction models by using two alternative classification algorithm, i.e., logistic regression and Naive Bayes. Table~\ref{tab:lr} shows the precision, recall and F1 scores on SSA vs. two different defect prediction models constructed by code features and semantic features using logistic regression. On average, code features and semantic features achieve F1 of 0.421 and 0.432 respectively. It shows that our SSA model improve the performance of F1 by 8.9\% and 7.8\% compared to two defect prediction models built using logistic regression algorithm. Table~\ref{tab:nb} presents the results of defect prediction models code features and semantic features using Naive Bayes algorithm, and SSA approaches. We see that our SSA outperforms these two baseline approaches. Table~\ref{tab:all} shows the F1 results of our approach compared to the two code features and semantic features constructed be three different machine learning algorithms, i.e., decision tree, logistic regression, and Naive Bayes. It shows that SSA outperforms the other approaches on 28 software projects in average. 

%The results demonstrate
%that by using the semantic features automatically learned
%by DBN instead of the PROMISE features, we can improve
%the defect prediction F1 by 14.2% on average on 16 data
%sets. The average improvement in the precision and recall is
%14.7% and 11.5% respectively.
%Since the DBN algorithm has randomness, the generated
%features vary between dierent runs. Therefore, we run our
%DBN-based feature generation approach ve times for each
%experiment. Among the runs, the dierence in the generated
%features is at the level of 1.0e-20, which is too small to
%propagate to precision, recall, and F1. In other words, the
%precision, recall, and F1 of all ve runs are identical.

