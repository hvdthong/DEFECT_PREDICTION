\subsection{Defect Prediction}
\label{sec:defect}
\input{defect}

The software defect prediction problem has been studied in the past decade~\cite{nam2013transfer, menzies2010defect, menzies2007data, zimmermann2007predicting, jiang2013personalized, nagappan2007using, nguyen2011topic, wang2012compressed}. Traditional approaches in defect prediction often manually extract features from historical defect data to construct machine learning classification model~\cite{menzies2010defect}. 
%McCabe et al.~\cite{mccabe1976complexity} introduced a graph-theoretic complexity measure for the control program elements which can be considered as a feature in defect prediction. CK features~\cite{chidamber1994metrics} focused on understanding of software development process, while MOOD features~\cite{harrison1998evaluation} provided an overall assessment of a software system to manage the software development projects. These features are widely used in defect prediction. 
Moser et al.~\cite{moser2008comparative} employed the number of revisions of a file, age of a file, number of authors that checked a file, etc. for defect prediction. Nagappan et al.~\cite{nagappan2007using} extracted features by considering relationship between its software
dependencies, churn measures and post-release failures to build a classification model for defect prediction. Lee et al.~\cite{lee2011micro} introduced 56 novel micro interaction metrics (MIMs) leveraging developers' interaction information stored in the Mylyn data, and shown that MIMs significantly improve the performance of defect classification. Jiang~\cite{jiang2013personalized} showed that individual characteristics and collaboration between developers were useful for defect prediction. 

Based on these features, classification models are built to predict the defect among program elements. Elish et al.~\cite{elish2008predicting} estimated the capability of Support Vector Machine (SVM)~\cite{suykens1999least} in predicting defect-prone software modules and showed that the prediction performance of SVM is generally better than eight statistical and machine learning models in NASA datasets. Amasaki et al.~\cite{amasaki2003bayesian} employed Bayesian belief network (BBN)~\cite{mcabeebayesian} to predict the amount of residual faults of a software product. Khoshgoftaar et al.~\cite{khoshgoftaar2002tree}
showed that the Tree-based machine learning algorithms are efficiently in defect detection. Jing et al.~\cite{jing2014dictionary} proposed to use the dictionary learning technique to predict software defect. Typically, they introduced a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction.

The main differences between our approach and traditional approaches are as follows. First, existing approaches to defect prediction are based on manually encoded traditional features which are not sensitive to programs' semantic information, while our approach automatically learns semantic features using semi-supervised autoencoder. Second, these features are automatically employed to construct classification model for defect prediction tasks. 

%The software defect prediction has been studied in the past decade~\cite{nam2013transfer, menzies2010defect, menzies2007data, zimmermann2007predicting, jiang2013personalized, nagappan2007using, nguyen2011topic, wang2012compressed}. However, the traditional approaches in defect prediction often manually extract features from historical defect data to construct machine learning classification model~\cite{menzies2010defect}. McCabe et al.~\cite{mccabe1976complexity} introduced a graph-theoretic complexity measure for the control program elements which can be considered as a feature in defect prediction. CK features~\cite{chidamber1994metrics} focused on understanding of software development process, while MOOD features~\cite{harrison1998evaluation} provided an overall assessment of a software system to manage the software development projects. These features are widely used in defect prediction. Moser et al.~\cite{moser2008comparative} employed the number of revisions of a file, age of a file, number of authors that checked a file, etc. to defect prediction. Nagappan et al.~\cite{nagappan2007using} extracted features by considering relationship between its software
%dependencies, churn measures and post-release failures to build classification model for defect prediction. Lee et al.~\cite{lee2011micro} introduced 56 novel micro interaction metrics (MIMs) leveraging developers' interaction information stored in the Mylyn data, and shown that MIMs significantly improve the performance of defect classification. Jiang~\cite{jiang2013personalized} showed that individual characteristics and collaboration between developers were useful for defect prediction. 
%
%Based on these features, classification models are built to predict the defect among program elements. Elish et al.~\cite{elish2008predicting} estimated the capability of Support Vector Machine (SVM)~\cite{suykens1999least} in predicting defect-prone software modules and showed that the prediction performance of SVM is generally better than eight statistical and machine learning models in NASA datasets. Amasaki et al.~\cite{amasaki2003bayesian} employed Bayesian belief network (BBN)~\cite{mcabeebayesian} to predict the amount of residual faults of a software product. Khoshgoftaar et al.~\cite{khoshgoftaar2002tree}
%showed that the Tree-based machine learning algorithms are efficiently in defect detection. Jing et al.~\cite{jing2014dictionary} proposed to use the dictionary learning technique to predict software defect. Typically, they introduced a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction.
%
%The main differences between our approach and traditional approaches are as follows. First, existing approaches to defect prediction are based on manually encoded traditional features which are not sensitive to programs' semantic information, while our approach automatically learns semantic features using semi-supervised autoencoder. Second, these features are automatically employed to construct classification model for defect prediction tasks. 

%\textcolor{red}{Talking about the different between our approach with DBN approach}
%
%The main dierences between our approach and existing
%approaches for within-project defect prediction and cross-project defect prediction are as follows. First, existing ap-proaches to defect prediction are based on manually encoded
%traditional features which are not sensitive to programs' se-mantic information, while our approach automatically learns
%semantic features using DBN and uses these features to per-form defect prediction tasks. Second, since our approach re-quires only the source code of the training and test projects,
%it is suitable for both within-project defect prediction and
%cross-project defect prediction.

%many machine learning models
%are built for two dierent defect prediction tasks|within-project defect prediction and cross-project defect prediction.
 

%ages of les as features to predict defects. Nagappan et
%al. [40] proposed code churn features, and shown that these
%features were eective for defect prediction. Hassan et
%al. [12] used entropy of change features to predict defects.
%Lee et al. [27] proposed 56 micro interaction metrics to
%improve defect prediction. Other process features, including
%developer individual characteristics [18, 48] and collabora-tion between developers [27, 34, 51, 64], were also useful for
%defect prediction.

%Within-project defect prediction (WPDP) uses training
%data and test data that are from the same project. Many
%machine learning algorithms have been adopted for WPDP,
%including Support Vector Machine (SVM) [8], Bayesian
%Belief Network [1], Naive Bayes (NB) [59], Decision Tree
%(DT) [9, 21, 62], and Dictionary Learning [20].
%Elish et al. [8] evaluated the capability of SVM in predict-ing defect-prone software modules, and they compared SVM
%against eight statistical and machine learning models on four
%NASA datasets. Amasaki et al. [1] proposed an approach to
%predict the nal quality of a software product by using the
%Bayesian Belief Network. Tao et al. [59] proposed a Naive
%Bayes based defect prediction model, they evaluated the pro-posed approach on 11 datasets from the PROMISE defect
%data repository. Wang et al. [62] and Khoshgoftaar et al. [21]
%examined the performance of Tree-based machine learning
%algorithms on defect prediction, their results suggested that
%Tree-based algorithms could help defect prediction. Jing et
%al. [20] introduced the dictionary learning technique to de-fect prediction. They proposed a cost-sensitive dictionary
%learning based approach to improve defect prediction.

\subsection{Deep Learning in Software Engineering}
\label{sec:deeplearning}
\input{deeplearning}
