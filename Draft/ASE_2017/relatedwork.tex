\subsection{Defect Prediction}
\label{sec:defect}
\input{defect}

The software defect prediction problem has been studied in the past decade~\cite{nam2013transfer, menzies2010defect, menzies2007data, zimmermann2007predicting, jiang2013personalized, nagappan2007using, nguyen2011topic, wang2012compressed}. Traditional approaches in defect prediction often manually extract features from historical defect data to construct machine learning classification model~\cite{menzies2010defect}. 
%McCabe et al.~\cite{mccabe1976complexity} introduced a graph-theoretic complexity measure for the control program elements which can be considered as a feature in defect prediction. CK features~\cite{chidamber1994metrics} focused on understanding of software development process, while MOOD features~\cite{harrison1998evaluation} provided an overall assessment of a software system to manage the software development projects. These features are widely used in defect prediction. 
Moser et al.~\cite{moser2008comparative} employed the number of revisions of a file, age of a file, number of authors that checked a file, etc. for defect prediction. 
%Nagappan et al.~\cite{nagappan2007using} extracted features by considering relationship between its software
%dependencies, churn measures and post-release failures to build a classification model for defect prediction. 
Lee et al.~\cite{lee2011micro} introduced 56 novel micro interaction metrics (MIMs) leveraging developers' interaction information stored in the Mylyn data, and showed that MIMs significantly improve the performance of defect classification. Jiang~\cite{jiang2013personalized} showed that individual characteristics and collaboration between developers were useful for defect prediction. 

Based on these features, classification models are built to predict the defect among program elements. Elish et al.~\cite{elish2008predicting} estimated the capability of Support Vector Machine (SVM)~\cite{suykens1999least} in predicting defect-prone software modules and showed that the prediction performance of SVM is generally better than eight statistical and machine learning models in NASA datasets. Amasaki et al.~\cite{amasaki2003bayesian} employed Bayesian belief network (BBN)~\cite{mcabeebayesian} to predict the amount of residual faults of a software product. Khoshgoftaar et al.~\cite{khoshgoftaar2002tree}
showed that tree-based machine learning algorithms are effective for defect prediction. 
Jing et al.~\cite{jing2014dictionary} proposed to use dictionary learning technique to predict software defect. They introduced a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction.

%The main difference between our approach and traditional approaches lies in how features are constructed. Existing approaches to defect prediction are based on manually encoded traditional features which are not sensitive to programs' semantic information, while our approach automatically learns semantic features using deep discriminative autoencoder. %Second, these features are automatically employed to construct classification model for defect prediction tasks.

Wang et al.~\cite{wang2016automatically} employed DBN to learn semantic features from AST. These features are used to build defect prediction model. However, the features are learned from source files without considering their true label, hence maybe suboptimal for defect prediction purpose. To overcome this problem, we propose DDA model providing end-to-end learning framework to build semantic features and defect prediction model in one stage. 

%There are two relevant works that also learn semantic features~\cite{yang2015deep,wang2016automatically}. Yang et al.~\cite{yang2015deep} leveraged DBN to generate features from existing features and used these new features to predict whether a program element contains bugs. It showed that the deep learning algorithm helps to discover more bug than traditional approaches across six software projects. Existing features were manually designed based on change level: i.e., the number of modified subsystems, code added, code deleted, the number of files change, etc. Recently, Wang et al.~\cite{wang2016automatically} also employed DBN to learn semantic features from source code. Their features were extracted directly from AST since they claimed that Yang features~\cite{yang2015deep} were fail to distinguish semantic differences between different source code. However, these approaches  %An evaluation on ten popular source projects showed that semantic features significantly improve the performance of defect prediction. The above relevant works learn semantic features and build defect prediction model independently.%, thus the semantic features only learn from source code without considering the label of this program element which may decrease the performance of defect prediction model. 

%To simultaneously semantic features and build defect prediction model, we propose a deep discriminative autoencoder model.  We evaluate the effectiveness of our proposed approach against Wang approach~\cite{wang2012compressed} on four popular software projects and achieve a significant improvement.

%The software defect prediction has been studied in the past decade~\cite{nam2013transfer, menzies2010defect, menzies2007data, zimmermann2007predicting, jiang2013personalized, nagappan2007using, nguyen2011topic, wang2012compressed}. However, the traditional approaches in defect prediction often manually extract features from historical defect data to construct machine learning classification model~\cite{menzies2010defect}. McCabe et al.~\cite{mccabe1976complexity} introduced a graph-theoretic complexity measure for the control program elements which can be considered as a feature in defect prediction. CK features~\cite{chidamber1994metrics} focused on understanding of software development process, while MOOD features~\cite{harrison1998evaluation} provided an overall assessment of a software system to manage the software development projects. These features are widely used in defect prediction. Moser et al.~\cite{moser2008comparative} employed the number of revisions of a file, age of a file, number of authors that checked a file, etc. to defect prediction. Nagappan et al.~\cite{nagappan2007using} extracted features by considering relationship between its software
%dependencies, churn measures and post-release failures to build classification model for defect prediction. Lee et al.~\cite{lee2011micro} introduced 56 novel micro interaction metrics (MIMs) leveraging developers' interaction information stored in the Mylyn data, and shown that MIMs significantly improve the performance of defect classification. Jiang~\cite{jiang2013personalized} showed that individual characteristics and collaboration between developers were useful for defect prediction. 
%
%Based on these features, classification models are built to predict the defect among program elements. Elish et al.~\cite{elish2008predicting} estimated the capability of Support Vector Machine (SVM)~\cite{suykens1999least} in predicting defect-prone software modules and showed that the prediction performance of SVM is generally better than eight statistical and machine learning models in NASA datasets. Amasaki et al.~\cite{amasaki2003bayesian} employed Bayesian belief network (BBN)~\cite{mcabeebayesian} to predict the amount of residual faults of a software product. Khoshgoftaar et al.~\cite{khoshgoftaar2002tree}
%showed that the Tree-based machine learning algorithms are efficiently in defect detection. Jing et al.~\cite{jing2014dictionary} proposed to use the dictionary learning technique to predict software defect. Typically, they introduced a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction.
%
%The main differences between our approach and traditional approaches are as follows. First, existing approaches to defect prediction are based on manually encoded traditional features which are not sensitive to programs' semantic information, while our approach automatically learns semantic features using semi-supervised autoencoder. Second, these features are automatically employed to construct classification model for defect prediction tasks. 

%\textcolor{red}{Talking about the different between our approach with DBN approach}
%
%The main dierences between our approach and existing
%approaches for within-project defect prediction and cross-project defect prediction are as follows. First, existing ap-proaches to defect prediction are based on manually encoded
%traditional features which are not sensitive to programs' se-mantic information, while our approach automatically learns
%semantic features using DBN and uses these features to per-form defect prediction tasks. Second, since our approach re-quires only the source code of the training and test projects,
%it is suitable for both within-project defect prediction and
%cross-project defect prediction.

%many machine learning models
%are built for two dierent defect prediction tasks|within-project defect prediction and cross-project defect prediction.
 

%ages of les as features to predict defects. Nagappan et
%al. [40] proposed code churn features, and shown that these
%features were eective for defect prediction. Hassan et
%al. [12] used entropy of change features to predict defects.
%Lee et al. [27] proposed 56 micro interaction metrics to
%improve defect prediction. Other process features, including
%developer individual characteristics [18, 48] and collabora-tion between developers [27, 34, 51, 64], were also useful for
%defect prediction.

%Within-project defect prediction (WPDP) uses training
%data and test data that are from the same project. Many
%machine learning algorithms have been adopted for WPDP,
%including Support Vector Machine (SVM) [8], Bayesian
%Belief Network [1], Naive Bayes (NB) [59], Decision Tree
%(DT) [9, 21, 62], and Dictionary Learning [20].
%Elish et al. [8] evaluated the capability of SVM in predict-ing defect-prone software modules, and they compared SVM
%against eight statistical and machine learning models on four
%NASA datasets. Amasaki et al. [1] proposed an approach to
%predict the nal quality of a software product by using the
%Bayesian Belief Network. Tao et al. [59] proposed a Naive
%Bayes based defect prediction model, they evaluated the pro-posed approach on 11 datasets from the PROMISE defect
%data repository. Wang et al. [62] and Khoshgoftaar et al. [21]
%examined the performance of Tree-based machine learning
%algorithms on defect prediction, their results suggested that
%Tree-based algorithms could help defect prediction. Jing et
%al. [20] introduced the dictionary learning technique to de-fect prediction. They proposed a cost-sensitive dictionary
%learning based approach to improve defect prediction.

\subsection{Deep Learning in Software Engineering}
\label{sec:deeplearning}
\input{deeplearning}
