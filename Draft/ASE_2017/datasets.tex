% Table generated by Excel2LaTeX from sheet 'Analysis'
\begin{table*}[t!]
	\centering
	\caption{Description of four popular software projects.}
	\begin{tabular}{|l|l|r|c|c|}
		\hline
		Project & \multicolumn{1}{l|}{Description}  & \multicolumn{1}{l|}{Avg File} & \multicolumn{1}{l|}{Avg Bug (\%)} \\
		\hline
		\hline
		Checkstyle  &  a program to check whether source code conforms to coding standard & 433.5 & 30.9 \\
		NuvolaBase &  an add on to create, share, and exchange database in the cloud     & 1292.5 & 12.3 \\
		OrientDB &  a Multi-Model DBMS with document and graphe engine  & 1194.5 & 9.17 \\
		Traccar &  a server for various GPS tracking systems & 215   & 17.3 \\
		\hline
	\end{tabular}%
	\label{tab:data}%
\end{table*}%

We perform several steps to create our benchmark dataset. {\color{red}We do not use PROMISE defect dataset\footnote{\url{http://openscience.us/repo/defect/}} since the projects are very old (i.e., average age is around 10 years)}. Firstly, we fetch the latest top open-source Java projects from GitHub (sorted by the number of their stars and forks). We ignore projects with less than 150 source files as these projects are too small to employ deep neural network. We also filter out projects which have less than 100 tested files. For each remaining project, we extract two versions: training version (i.e., version as of January $1^{st}$, 2015), and testing version (i.e., version as of July $1^{st}$, 2015). 

For labeling training version, we extract commits between January $1^{st}$, 2015 to July $1^{st}$ 2015. We then identify bug fixing commits by checking whether the commit message contains a bug fixing pattern. We follow the pattern used by Antoniol et al.~\cite{antoniol2008bug} as follows.
\[
\backslash bfix|\backslash bbug|\backslash bproblem|\backslash bdefect|\backslash bpatch
\]
We consider changed files in bug fixing commits as buggy files and label their corresponding files (i.e., files of the same path) in training version as buggy. For labeling testing version, we extract commits between July $1^{st}$, 2015 to January $1^{st}$ 2016 and perform the same labeling process that was done for the training version.

We analyze four projects as the dataset for our preliminary experiment. Table~\ref{tab:data} shows statistics on this dataset. In average, our dataset contains around 783.88 source files with bug rate of 17.4\%, showing the imbalanced problem in defect prediction~\cite{wang2013using, khoshgoftaar2010attribute}.

%We perform several steps to create our benchmark dataset. Firstly, we fetch top 2,500 most popular open-source Java projects from GitHub (sorted by the sum of their number of stars and number of forks). GitHub contains many toy projects, thus, we only consider popular projects similar to prior studies~\cite{ray2014large, kochhar2016large}. We only clone the git repositories of projects which use Maven as we leverage Maven to automatically build the projects and construct call graphs from compiled classes. Out of the 2500 projects, 831 projects use Maven. Secondly, we collect 342 Apache Java projects which use Maven and are hosted on GitHub. A er removing the overlapping projects, our dataset contains 1,143 projects.

%Next, we ignore projects with less than 150 source files as these projects are too small to employ deep neural netwok. We also  filter out projects which have less than 100 tested files. For each project, we have two versions: current version (i.e., latest version as of June 2016) which serves as a test dataset, and previous version (i.e., version one year prior to current version) which serves as a training set. We compile these two versions using \textit{mvn compile:compile}. We ignore projects whose current and/or previous version cannot be compiled. In the end, our dataset has 28 projects.

%Table~\ref{tab:data} shows the overview of our dataset containing 28 projects. In average, our data has around 921 source files in training set and more than 1020 program elements in testing set. Average bug rate is 18.7\% and 7.5\% on training and testing data respectively showing the imbalanced problem in defect prediction~\cite{wang2013using, khoshgoftaar2010attribute}. 

%having a total of 46 million SLOC, 83 thousand source code  les, 0.9 million methods, 280 thousand commits and over 45 thousand test  les contributed by more than 5 thousand developers spanning over period of 15 years, i.e., 2001-2016. Our dataset con- tains popular projects such as Apache Commons IO [4], which is a library of utilities for IO functionalities and Joda-Time [31], which is date and time library for Java.